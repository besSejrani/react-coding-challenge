{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Index Aspaara Coding Challenge At aspaara a squad of superheroes work on giving superpowers to planning teams. Through our product dashboard we give insights into data \u2013 a true super-vision superpower. Join forces with us and build a dashboard of the future! Goal Create a simple single-page application that allows a planner to get insights into client and planning information. You will find the corresponding data to display in planning.json , which contains around 10k records. Requirements Within the application, it should be possible to browse all the data that is provided in planning.json in a detailed view (for example table view) get an overview of the data with some statistics, for at least on of the following attributes: booking grade office city skills industry drill down into subsets by means of filtering and/or sorting Data Model ID: integer (unique, required) Original ID: string (unique, required) Talent ID: string (optional) Talent Name: string (optional) Talent Grade: string (optional) Booking Grade: string (optional) Operating Unit: string (required) Office City: string (optional) Office Postal Code: string (required) Job Manager Name: string (optional) Job Manager ID: string (optional) Total Hours: float (required) Start Date: datetime (required) End Date: datetime (required) Client Name: string (optional) Client ID: string (required) Industry: string (optional) Required Skills: array of key-value pair (optional) Optional Skills: array of key-value pair (optional) Is Unassigned: boolean Tech Stack JavaScript or TypeScript React Node (if required) Submission Please fork the project, commit and push your implementation and add sundara.amancharla@aspaara.com as a contributor. Please update the README with any additional details or steps that are requried to run your implementation. We understand that there is a limited amount of time, so it does not have to be perfect or 100% finished. Plan to spend no more than 2-3 hours on it. For any additional questions on the task please feel free to email sundara.amancharla@aspaara.com .","title":"Index"},{"location":"#index","text":"","title":"Index"},{"location":"#aspaara-coding-challenge","text":"At aspaara a squad of superheroes work on giving superpowers to planning teams. Through our product dashboard we give insights into data \u2013 a true super-vision superpower. Join forces with us and build a dashboard of the future!","title":"Aspaara Coding Challenge"},{"location":"#goal","text":"Create a simple single-page application that allows a planner to get insights into client and planning information. You will find the corresponding data to display in planning.json , which contains around 10k records.","title":"Goal"},{"location":"#requirements","text":"Within the application, it should be possible to browse all the data that is provided in planning.json in a detailed view (for example table view) get an overview of the data with some statistics, for at least on of the following attributes: booking grade office city skills industry drill down into subsets by means of filtering and/or sorting","title":"Requirements"},{"location":"#data-model","text":"ID: integer (unique, required) Original ID: string (unique, required) Talent ID: string (optional) Talent Name: string (optional) Talent Grade: string (optional) Booking Grade: string (optional) Operating Unit: string (required) Office City: string (optional) Office Postal Code: string (required) Job Manager Name: string (optional) Job Manager ID: string (optional) Total Hours: float (required) Start Date: datetime (required) End Date: datetime (required) Client Name: string (optional) Client ID: string (required) Industry: string (optional) Required Skills: array of key-value pair (optional) Optional Skills: array of key-value pair (optional) Is Unassigned: boolean","title":"Data Model"},{"location":"#tech-stack","text":"JavaScript or TypeScript React Node (if required)","title":"Tech Stack"},{"location":"#submission","text":"Please fork the project, commit and push your implementation and add sundara.amancharla@aspaara.com as a contributor. Please update the README with any additional details or steps that are requried to run your implementation. We understand that there is a limited amount of time, so it does not have to be perfect or 100% finished. Plan to spend no more than 2-3 hours on it. For any additional questions on the task please feel free to email sundara.amancharla@aspaara.com .","title":"Submission"},{"location":"checklist/","text":"Check List Software installation Install Make Install Node.js Install Docker Install Docker-Compose Environment variables Create Client .env file Create Server .env file Create Script .env file Install the dependencies Install dependencies in the Client folder Install dependencies in the Server folder Install dependencies in the Script folder Launch order Launch the make run-dev-build command Launch the npm run start command in the Script folder for importing the data of the json.file into the database.","title":"Check List"},{"location":"checklist/#check-list","text":"","title":"Check List"},{"location":"checklist/#software-installation","text":"Install Make Install Node.js Install Docker Install Docker-Compose","title":"Software installation"},{"location":"checklist/#environment-variables","text":"Create Client .env file Create Server .env file Create Script .env file","title":"Environment variables"},{"location":"checklist/#install-the-dependencies","text":"Install dependencies in the Client folder Install dependencies in the Server folder Install dependencies in the Script folder","title":"Install the dependencies"},{"location":"checklist/#launch-order","text":"Launch the make run-dev-build command Launch the npm run start command in the Script folder for importing the data of the json.file into the database.","title":"Launch order"},{"location":"preparation/","text":"Project Boilerplate code Having worked with React and Node.js for 3 years now (non-professionally), I had a lot of code snippets and projects already done. I didn't want to reinvent the wheel, so I used my existing code from other projects, especially BlueberryShop and ChillMovie . Time constraints I tried to stick as much as possible to the time constraints, therefore, I couldn't finish the statistics page with interactive charts. The planning details page is finished, but it isn't polished.","title":"Project"},{"location":"preparation/#project","text":"","title":"Project"},{"location":"preparation/#boilerplate-code","text":"Having worked with React and Node.js for 3 years now (non-professionally), I had a lot of code snippets and projects already done. I didn't want to reinvent the wheel, so I used my existing code from other projects, especially BlueberryShop and ChillMovie .","title":"Boilerplate code"},{"location":"preparation/#time-constraints","text":"I tried to stick as much as possible to the time constraints, therefore, I couldn't finish the statistics page with interactive charts. The planning details page is finished, but it isn't polished.","title":"Time constraints"},{"location":"1.Installation/0.Make/","text":"Make Use Case Make allows to automate a program's build process. By installing the project via containers, make is mostly used to inject a environment variable to Docker-Compose which will then be injected in the application. Makefile # Production run-prod : ENVIRONMENT = production \\ docker-compose up # Development run-dev : ENVIRONMENT = development \\ docker-compose up run-dev-build : ENVIRONMENT = development \\ docker-compose up --build --remove-orphans Installation Windows Brew Linux Make for Windows can be installed via the following link . Don't forget to add Make's path to your environment variables if the installer doesn't do it automatically. brew install make # Update & upgrade packages sudo apt update sudo apt upgrade # Install Make sudo apt install make Containers List Containers Stop Containers Delete All Docker Containers & Volumes docker-compose ps docker-compose down docker system prune Running Services Service Port Client 3000 Server 4000 Mkdocs 9000 MongoDB 27017 Sources Source Author Link Make for Windows Sourceforge Link","title":"Make"},{"location":"1.Installation/0.Make/#make","text":"","title":"Make"},{"location":"1.Installation/0.Make/#use-case","text":"Make allows to automate a program's build process. By installing the project via containers, make is mostly used to inject a environment variable to Docker-Compose which will then be injected in the application. Makefile # Production run-prod : ENVIRONMENT = production \\ docker-compose up # Development run-dev : ENVIRONMENT = development \\ docker-compose up run-dev-build : ENVIRONMENT = development \\ docker-compose up --build --remove-orphans","title":"Use Case"},{"location":"1.Installation/0.Make/#installation","text":"Windows Brew Linux Make for Windows can be installed via the following link . Don't forget to add Make's path to your environment variables if the installer doesn't do it automatically. brew install make # Update & upgrade packages sudo apt update sudo apt upgrade # Install Make sudo apt install make","title":"Installation"},{"location":"1.Installation/0.Make/#containers","text":"List Containers Stop Containers Delete All Docker Containers & Volumes docker-compose ps docker-compose down docker system prune","title":"Containers"},{"location":"1.Installation/0.Make/#running-services","text":"Service Port Client 3000 Server 4000 Mkdocs 9000 MongoDB 27017","title":"Running Services"},{"location":"1.Installation/0.Make/#sources","text":"Source Author Link Make for Windows Sourceforge Link","title":"Sources"},{"location":"1.Installation/1.Docker/","text":"Docker Installation This project relies on Docker, please make sure it is installed on your system, documentation can be found here . Configuration Dockerfile Example FROM node:alpine as builder WORKDIR /app COPY package*.json . RUN npm install --force COPY . . EXPOSE 3000 CMD [\"npm\", \"run\", \"dev\"] Sources Source Author Link Install Docker Engine on Ubuntu Docker Link","title":"Docker"},{"location":"1.Installation/1.Docker/#docker","text":"","title":"Docker"},{"location":"1.Installation/1.Docker/#installation","text":"This project relies on Docker, please make sure it is installed on your system, documentation can be found here .","title":"Installation"},{"location":"1.Installation/1.Docker/#configuration","text":"Dockerfile Example FROM node:alpine as builder WORKDIR /app COPY package*.json . RUN npm install --force COPY . . EXPOSE 3000 CMD [\"npm\", \"run\", \"dev\"]","title":"Configuration"},{"location":"1.Installation/1.Docker/#sources","text":"Source Author Link Install Docker Engine on Ubuntu Docker Link","title":"Sources"},{"location":"1.Installation/2.Docker-Compose/","text":"Docker-Compose Installation For better container management, docker-compose is used in development, make sure as well, that it is installed on your system, documentation can be found here . Configuration For custom configuration, the docker-compose.yaml file can be edited to match your use case, documentation can be found here . docker-compose.yaml Example version : \"3.8\" services : #==================================================== # Documentation #==================================================== mkdocs : restart : always container_name : mkdocs build : dockerfile : Dockerfile context : ./Documentation ports : - \"9000:8000\" volumes : - ./Documentation:/app #==================================================== # Client #==================================================== client : build : context : ./Client container_name : client networks : - frontend ports : - \"3000:3000\" depends_on : - server volumes : - ./Client:/app #==================================================== # Server #==================================================== server : build : context : ./Server container_name : server networks : - backend - frontend ports : - \"4000:4000\" depends_on : - mongo environment : - NODE_ENV2=${ENVIRONMENT} env_file : - ./Server/.env volumes : - ./Server:/app #==================================================== # MongoDB #==================================================== mongo : container_name : mongodb image : mongo:latest restart : always ports : - 27017:27017 networks : - backend environment : MONGO_INITDB_ROOT_USERNAME : root MONGO_INITDB_ROOT_PASSWORD : password MONGO_INITDB_DATABASE : root-db volumes : - ./Mongo/mongo-init.js:/docker-entrypoint-initdb.d/mongo-init.js:ro - ~/docker/aspaara/Mongo:/data/db # =========================================================================================================================== networks : backend : frontend : Sources Source Author Link Install Docker Compose Docker Link","title":"Docker-Compose"},{"location":"1.Installation/2.Docker-Compose/#docker-compose","text":"","title":"Docker-Compose"},{"location":"1.Installation/2.Docker-Compose/#installation","text":"For better container management, docker-compose is used in development, make sure as well, that it is installed on your system, documentation can be found here .","title":"Installation"},{"location":"1.Installation/2.Docker-Compose/#configuration","text":"For custom configuration, the docker-compose.yaml file can be edited to match your use case, documentation can be found here . docker-compose.yaml Example version : \"3.8\" services : #==================================================== # Documentation #==================================================== mkdocs : restart : always container_name : mkdocs build : dockerfile : Dockerfile context : ./Documentation ports : - \"9000:8000\" volumes : - ./Documentation:/app #==================================================== # Client #==================================================== client : build : context : ./Client container_name : client networks : - frontend ports : - \"3000:3000\" depends_on : - server volumes : - ./Client:/app #==================================================== # Server #==================================================== server : build : context : ./Server container_name : server networks : - backend - frontend ports : - \"4000:4000\" depends_on : - mongo environment : - NODE_ENV2=${ENVIRONMENT} env_file : - ./Server/.env volumes : - ./Server:/app #==================================================== # MongoDB #==================================================== mongo : container_name : mongodb image : mongo:latest restart : always ports : - 27017:27017 networks : - backend environment : MONGO_INITDB_ROOT_USERNAME : root MONGO_INITDB_ROOT_PASSWORD : password MONGO_INITDB_DATABASE : root-db volumes : - ./Mongo/mongo-init.js:/docker-entrypoint-initdb.d/mongo-init.js:ro - ~/docker/aspaara/Mongo:/data/db # =========================================================================================================================== networks : backend : frontend :","title":"Configuration"},{"location":"1.Installation/2.Docker-Compose/#sources","text":"Source Author Link Install Docker Compose Docker Link","title":"Sources"},{"location":"1.Installation/3.nodejs/","text":"Node.js Install Node.js Windows MacOS Linux Node Version NPM Version Don't forget to add Node's path to your environement variables if the installer doesn't do it automatically. Image: Node.js Windows Installation Image: Node.js MacOS Installation cd ~ curl -sL https://deb.nodesource.com/setup_14.x -o nodesource_setup.sh nano nodesource_setup.sh sudo bash nodesource_setup.sh sudo apt install nodejs node -v node -v NPM is the official Node Package Manager of Node.js, it comes with Node. npm -v Install Project Dependencies Client Server // NPM cd Client npm install // Yarn cd Client yarn install // NPM cd Server npm install // Yarn cd Server yarn install Run Application Script // NPM cd Server npm run dev // Yarn cd Server yarn run dev Sources Source Author Link How To Install Node.js on Ubuntu 20.04 Digital Ocean Link","title":"Node.js"},{"location":"1.Installation/3.nodejs/#nodejs","text":"","title":"Node.js"},{"location":"1.Installation/3.nodejs/#install-nodejs","text":"Windows MacOS Linux Node Version NPM Version Don't forget to add Node's path to your environement variables if the installer doesn't do it automatically. Image: Node.js Windows Installation Image: Node.js MacOS Installation cd ~ curl -sL https://deb.nodesource.com/setup_14.x -o nodesource_setup.sh nano nodesource_setup.sh sudo bash nodesource_setup.sh sudo apt install nodejs node -v node -v NPM is the official Node Package Manager of Node.js, it comes with Node. npm -v","title":"Install Node.js"},{"location":"1.Installation/3.nodejs/#install-project-dependencies","text":"Client Server // NPM cd Client npm install // Yarn cd Client yarn install // NPM cd Server npm install // Yarn cd Server yarn install","title":"Install Project Dependencies"},{"location":"1.Installation/3.nodejs/#run-application","text":"Script // NPM cd Server npm run dev // Yarn cd Server yarn run dev","title":"Run Application"},{"location":"1.Installation/3.nodejs/#sources","text":"Source Author Link How To Install Node.js on Ubuntu 20.04 Digital Ocean Link","title":"Sources"},{"location":"2.Client/0.react/","text":"React Brief Although it was stated in the project brief that React would be used, Next.js or Gatsby could also have been used. But since it wasn't clear if it would have been used with SEO in mind, Aspaara Planning was built in Vanilla React.","title":"React"},{"location":"2.Client/0.react/#react","text":"","title":"React"},{"location":"2.Client/0.react/#brief","text":"Although it was stated in the project brief that React would be used, Next.js or Gatsby could also have been used. But since it wasn't clear if it would have been used with SEO in mind, Aspaara Planning was built in Vanilla React.","title":"Brief"},{"location":"2.Client/1.ui/","text":"UI Library Material UI For Aspaara Planning, Material UI was chosen since it provides already built-in components. Other solutions, like styled components , could have been used, but due to the time constraint, this solution wasn't viable. Any other UI library could have been used instead of Material UI, like Chakra or Tailwindcss . Having experience with Material UI, I went this route, trying to spend the least amount of time possible. Library Library URI Description Material UI Link Material-UI is a UI library component kit built on Google's material design system.","title":"UI Library"},{"location":"2.Client/1.ui/#ui-library","text":"","title":"UI Library"},{"location":"2.Client/1.ui/#material-ui","text":"For Aspaara Planning, Material UI was chosen since it provides already built-in components. Other solutions, like styled components , could have been used, but due to the time constraint, this solution wasn't viable. Any other UI library could have been used instead of Material UI, like Chakra or Tailwindcss . Having experience with Material UI, I went this route, trying to spend the least amount of time possible.","title":"Material UI"},{"location":"2.Client/1.ui/#library","text":"Library URI Description Material UI Link Material-UI is a UI library component kit built on Google's material design system.","title":"Library"},{"location":"2.Client/2.state/","text":"State Management Redux Redux was chosen as the state management solution over the Context API since I have experience with it, and implementing it was quite fast. Although I implemented it because of my experience and the time constraints, Redux is supported by a large community with third party libraries and a lot of Stackoverflow questions already answered. Other State Management Solution Other state management solutions could have been used, like Apollo client for GraphQL, but since it handles GraphQL queries, this implies that there are some changes to be made on the server. For this project, I wanted a small and fast solution.","title":"State Management"},{"location":"2.Client/2.state/#state-management","text":"","title":"State Management"},{"location":"2.Client/2.state/#redux","text":"Redux was chosen as the state management solution over the Context API since I have experience with it, and implementing it was quite fast. Although I implemented it because of my experience and the time constraints, Redux is supported by a large community with third party libraries and a lot of Stackoverflow questions already answered.","title":"Redux"},{"location":"2.Client/2.state/#other-state-management-solution","text":"Other state management solutions could have been used, like Apollo client for GraphQL, but since it handles GraphQL queries, this implies that there are some changes to be made on the server. For this project, I wanted a small and fast solution.","title":"Other State Management Solution"},{"location":"2.Client/3.configuration/","text":"Configuration Relative Imports Importing long relative paths for a large number of components can be time-consuming, which is why paths to relative folders are already set in the tsconfig.json file. Tsconfig.json craco.config.js { \"compilerOptions\" : { \"baseUrl\" : \".\" , \"paths\" : { \"@Types/*\" : [ \"./Types/*\" ], \"@Components/*\" : [ \"./src/Components/*\" ], \"@Pages/*\" : [ \"./src/Pages/*\" ], \"@Hooks/*\" : [ \"./src/Hooks/*\" ], \"@Redux/*\" : [ \"./src/Redux/*\" ], \"@Layout/*\" : [ \"./src/Layout/*\" ], \"@Assets/*\" : [ \"./src/Assets/*\" ] } } } const path = require ( \"path\" ); module . exports = { webpack : { alias : { \"@Types\" : path . resolve ( ** dirname , \"./types\" ), \"@Components\" : path . resolve ( ** dirname , \"./src/Components\" ), \"@Pages\" : path . resolve ( ** dirname , \"./src/Pages\" ), \"@Hooks\" : path . resolve ( ** dirname , \"./src/Hooks\" ), \"@Redux\" : path . resolve ( ** dirname , \"./src/Redux\" ), \"@Layout\" : path . resolve ( ** dirname , \"./src/Layout\" ), \"@Assets\" : path . resolve ( \\ _ \\ _dirname , \"./src/Assets\" ), }, }, }; Although there is no use of using environment variables from a security perspective on the frontend, for configuration reasons, it is quiet helpful. Please create an .env file at the root of the Client folder. .env REACT_APP_SERVER = http : //localhost:4000","title":"Configuration"},{"location":"2.Client/3.configuration/#configuration","text":"","title":"Configuration"},{"location":"2.Client/3.configuration/#relative-imports","text":"Importing long relative paths for a large number of components can be time-consuming, which is why paths to relative folders are already set in the tsconfig.json file. Tsconfig.json craco.config.js { \"compilerOptions\" : { \"baseUrl\" : \".\" , \"paths\" : { \"@Types/*\" : [ \"./Types/*\" ], \"@Components/*\" : [ \"./src/Components/*\" ], \"@Pages/*\" : [ \"./src/Pages/*\" ], \"@Hooks/*\" : [ \"./src/Hooks/*\" ], \"@Redux/*\" : [ \"./src/Redux/*\" ], \"@Layout/*\" : [ \"./src/Layout/*\" ], \"@Assets/*\" : [ \"./src/Assets/*\" ] } } } const path = require ( \"path\" ); module . exports = { webpack : { alias : { \"@Types\" : path . resolve ( ** dirname , \"./types\" ), \"@Components\" : path . resolve ( ** dirname , \"./src/Components\" ), \"@Pages\" : path . resolve ( ** dirname , \"./src/Pages\" ), \"@Hooks\" : path . resolve ( ** dirname , \"./src/Hooks\" ), \"@Redux\" : path . resolve ( ** dirname , \"./src/Redux\" ), \"@Layout\" : path . resolve ( ** dirname , \"./src/Layout\" ), \"@Assets\" : path . resolve ( \\ _ \\ _dirname , \"./src/Assets\" ), }, }, }; Although there is no use of using environment variables from a security perspective on the frontend, for configuration reasons, it is quiet helpful. Please create an .env file at the root of the Client folder. .env REACT_APP_SERVER = http : //localhost:4000","title":"Relative Imports"},{"location":"3.Server/0.rest/","text":"REST API Project Since it doesn't make sense to load 10,000 entries on the frontend via the planning.json file, it was decided to create a small API that would handle the pagination and individual requests. Express was chosen for implementing the API. index.ts // Environement variables import \"dotenv/config\" ; // Express import express from \"express\" ; // Database import mongo from \"../Models/mongo\" ; // Configuration import cors from \"cors\" ; import helmet from \"helmet\" ; // Routes import PlanningRoutes from \"../Routes/plannings\" ; // ======================================================================================================== const app = express (); // CORS Configuration const corsOptions = { origin : process.env.CORS_DOMAIN , credentials : true , }; // Middlewares app . use ( helmet ()); app . use ( cors ( corsOptions )); app . use ( express . urlencoded ({ extended : false })); app . use ( express . json ()); // Services mongo (); // Routes app . use ( \"/\" , PlanningRoutes ); // Listen to server const port = process . env . PORT || 6000 ; app . listen ( port , () => console . log ( `Server is running on port ${ port } ` ));","title":"REST API"},{"location":"3.Server/0.rest/#rest-api","text":"","title":"REST API"},{"location":"3.Server/0.rest/#project","text":"Since it doesn't make sense to load 10,000 entries on the frontend via the planning.json file, it was decided to create a small API that would handle the pagination and individual requests. Express was chosen for implementing the API. index.ts // Environement variables import \"dotenv/config\" ; // Express import express from \"express\" ; // Database import mongo from \"../Models/mongo\" ; // Configuration import cors from \"cors\" ; import helmet from \"helmet\" ; // Routes import PlanningRoutes from \"../Routes/plannings\" ; // ======================================================================================================== const app = express (); // CORS Configuration const corsOptions = { origin : process.env.CORS_DOMAIN , credentials : true , }; // Middlewares app . use ( helmet ()); app . use ( cors ( corsOptions )); app . use ( express . urlencoded ({ extended : false })); app . use ( express . json ()); // Services mongo (); // Routes app . use ( \"/\" , PlanningRoutes ); // Listen to server const port = process . env . PORT || 6000 ; app . listen ( port , () => console . log ( `Server is running on port ${ port } ` ));","title":"Project"},{"location":"3.Server/1.configuration/","text":"Configuration Environment Variables Warning Environment Variables are sensible information injected just before a server is starting. Don't forget to add the environment variable file to .gitignore, otherwise bots will scrape GitHub for sensible information. Please place an .env file in the root of the Server folder. You can copy the following example, the values are correct, except for the uppercase strings, which should be modified. .env # You can chose another port than 4000, but changes must also be made in the client .env file PORT = 4000 # MongoDB Atlas credentials, change the values in UPPERCASE MONGO_ATLAS = mongodb+srv://USER:PASSWORD@HOST/DATABASE?retryWrites = true & w = majority MONGO_PRODUCTION = mongodb://api_user:api1234@mongodb/api_prod_db?authSource = api_prod_db & readPreference = primary & appname = MongoDB%20Compass & ssl = false MONGO_DEVELOPMENT = mongodb://api_user:api1234@mongodb/api_dev_db?authSource = api_dev_db & readPreference = primary & appname = MongoDB%20Compass & ssl = false # Cross-Origin Resource Sharing configuration value, http://localhost:3000 CORS_DOMAIN = http://localhost:3000","title":"Configuration"},{"location":"3.Server/1.configuration/#configuration","text":"","title":"Configuration"},{"location":"3.Server/1.configuration/#environment-variables","text":"Warning Environment Variables are sensible information injected just before a server is starting. Don't forget to add the environment variable file to .gitignore, otherwise bots will scrape GitHub for sensible information. Please place an .env file in the root of the Server folder. You can copy the following example, the values are correct, except for the uppercase strings, which should be modified. .env # You can chose another port than 4000, but changes must also be made in the client .env file PORT = 4000 # MongoDB Atlas credentials, change the values in UPPERCASE MONGO_ATLAS = mongodb+srv://USER:PASSWORD@HOST/DATABASE?retryWrites = true & w = majority MONGO_PRODUCTION = mongodb://api_user:api1234@mongodb/api_prod_db?authSource = api_prod_db & readPreference = primary & appname = MongoDB%20Compass & ssl = false MONGO_DEVELOPMENT = mongodb://api_user:api1234@mongodb/api_dev_db?authSource = api_dev_db & readPreference = primary & appname = MongoDB%20Compass & ssl = false # Cross-Origin Resource Sharing configuration value, http://localhost:3000 CORS_DOMAIN = http://localhost:3000","title":"Environment Variables"},{"location":"4.Database/1.mongodb/","text":"MongoDB Schemaless Database Due to time constraints, the MongoDB database was chosen for its schemaless feature. Mongoose.js was chosen as the ORM. Database Connection Typescript // Configuration import \"dotenv/config\" ; // Mongoose import mongoose from \"mongoose\" ; // ============================================ export default async () => { let connection ; if ( process . env . NODE_ENV2 === \"production\" ) { connection = process . env . MONGO_PRODUCTION ; } if ( process . env . NODE_ENV2 === \"development\" ) { connection = process . env . MONGO_DEVELOPMENT ; } try { await mongoose . connect ( connection || process . env . MONGO_ATLAS ! ); await console . log ( \"Connected to database\" ); } catch ( error ) { console . log ( error . message ); console . log ( \"Couldn't connect to database\" ); } }; Development, Production Database When using docker-compose with Make , Docker creates two distinct databases for multiple environments, one for development and one for production. The following Javascript code is injected when Docker starts MongoDB; it creates two users with their roles and credentials. print ( \"Start #################################################################\" ); // Production db = db . getSiblingDB ( \"api_prod_db\" ); db . createCollection ( \"users\" ); db . createUser ({ user : \"root\" , pwd : \"password\" , roles : [{ role : \"userAdminAnyDatabase\" , db : \"api_prod_db\" }], }); // ======================================================================================================== // Developpement db = db . getSiblingDB ( \"api_dev_db\" ); db . createCollection ( \"users\" ); db . createUser ({ user : \"root\" , pwd : \"password\" , roles : [{ role : \"userAdminAnyDatabase\" , db : \"api_dev_db\" }], }); print ( \"END #################################################################\" ); Sources Source Kind URI MongoDB University Tutorial Link MongoDB Documentation Documentation Link","title":"MongoDB"},{"location":"4.Database/1.mongodb/#mongodb","text":"","title":"MongoDB"},{"location":"4.Database/1.mongodb/#schemaless-database","text":"Due to time constraints, the MongoDB database was chosen for its schemaless feature. Mongoose.js was chosen as the ORM.","title":"Schemaless Database"},{"location":"4.Database/1.mongodb/#database-connection","text":"Typescript // Configuration import \"dotenv/config\" ; // Mongoose import mongoose from \"mongoose\" ; // ============================================ export default async () => { let connection ; if ( process . env . NODE_ENV2 === \"production\" ) { connection = process . env . MONGO_PRODUCTION ; } if ( process . env . NODE_ENV2 === \"development\" ) { connection = process . env . MONGO_DEVELOPMENT ; } try { await mongoose . connect ( connection || process . env . MONGO_ATLAS ! ); await console . log ( \"Connected to database\" ); } catch ( error ) { console . log ( error . message ); console . log ( \"Couldn't connect to database\" ); } };","title":"Database Connection"},{"location":"4.Database/1.mongodb/#development-production-database","text":"When using docker-compose with Make , Docker creates two distinct databases for multiple environments, one for development and one for production. The following Javascript code is injected when Docker starts MongoDB; it creates two users with their roles and credentials. print ( \"Start #################################################################\" ); // Production db = db . getSiblingDB ( \"api_prod_db\" ); db . createCollection ( \"users\" ); db . createUser ({ user : \"root\" , pwd : \"password\" , roles : [{ role : \"userAdminAnyDatabase\" , db : \"api_prod_db\" }], }); // ======================================================================================================== // Developpement db = db . getSiblingDB ( \"api_dev_db\" ); db . createCollection ( \"users\" ); db . createUser ({ user : \"root\" , pwd : \"password\" , roles : [{ role : \"userAdminAnyDatabase\" , db : \"api_dev_db\" }], }); print ( \"END #################################################################\" );","title":"Development, Production Database"},{"location":"4.Database/1.mongodb/#sources","text":"Source Kind URI MongoDB University Tutorial Link MongoDB Documentation Documentation Link","title":"Sources"},{"location":"5.Script/1.import/","text":"Configuration Please place an .env file in the Script folder's root. You can copy the following example, the values are correct. .env MONGO_DEVELOPMENT = mongodb : //api_user:api1234@localhost:27017/api_dev_db?authMechanism=DEFAULT&authSource=api_dev_db MONGO_PRODUCTION = mongodb : //api_user:api1234@localhost:27017/api_prod_db?authMechanism=DEFAULT&authSource=api_prod_db Installation Install the required dependencies NPM Yarn npm install yarn install Execution NPM Yarn npm run start yarn run start","title":"Configuration"},{"location":"5.Script/1.import/#configuration","text":"Please place an .env file in the Script folder's root. You can copy the following example, the values are correct. .env MONGO_DEVELOPMENT = mongodb : //api_user:api1234@localhost:27017/api_dev_db?authMechanism=DEFAULT&authSource=api_dev_db MONGO_PRODUCTION = mongodb : //api_user:api1234@localhost:27017/api_prod_db?authMechanism=DEFAULT&authSource=api_prod_db","title":"Configuration"},{"location":"5.Script/1.import/#installation","text":"Install the required dependencies NPM Yarn npm install yarn install","title":"Installation"},{"location":"5.Script/1.import/#execution","text":"NPM Yarn npm run start yarn run start","title":"Execution"},{"location":"5.Script/2.backup/","text":"Backups MongoDB backups can be created using the command-line tools mongodump and mongorestore . In the Script folder, bash scripts are already available. Backup Script Restoration Script mongodump --host localhost:27017 \\ --username api_user \\ --password api1234 \\ --db api_dev_db \\ --gzip \\ --out ../Backup/ ` date + \"%Y-%m-%d\" ` mongorestore -d api_dev_db --host localhost:27017 \\ --username api_user \\ --password api1234 \\ --authenticationDatabase api_dev_db \\ --dir ../Backup/ ` date + \"%Y-%m-%d\" /api_dev_db ` \\ --gzip Sources Source Athor Link mongodump MongoDB Documentation Link mongorestore MongoDB Documentation Link","title":"Backups"},{"location":"5.Script/2.backup/#backups","text":"MongoDB backups can be created using the command-line tools mongodump and mongorestore . In the Script folder, bash scripts are already available. Backup Script Restoration Script mongodump --host localhost:27017 \\ --username api_user \\ --password api1234 \\ --db api_dev_db \\ --gzip \\ --out ../Backup/ ` date + \"%Y-%m-%d\" ` mongorestore -d api_dev_db --host localhost:27017 \\ --username api_user \\ --password api1234 \\ --authenticationDatabase api_dev_db \\ --dir ../Backup/ ` date + \"%Y-%m-%d\" /api_dev_db ` \\ --gzip","title":"Backups"},{"location":"5.Script/2.backup/#sources","text":"Source Athor Link mongodump MongoDB Documentation Link mongorestore MongoDB Documentation Link","title":"Sources"}]}